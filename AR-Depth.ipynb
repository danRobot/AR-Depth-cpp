{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "This source code is licensed under the MIT license found in the\n",
    "LICENSE file in the root directory of this source tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import DISOpticalFlow\n",
    "import numpy as np\n",
    "from pyquaternion import Quaternion\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import copy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "#### Dependencies: \n",
    "- OpenCV 4.0\n",
    "- opencv-contrib (`pip install opencv-contrib-python`)\n",
    "- NumPy\n",
    "- pyquaternion (`pip install pyquaternion`)\n",
    "\n",
    "#### First, make sure it runs on the test sequence:\n",
    "- Above, press `Cell > Run All`\n",
    "- Make sure the 'output' folder is populated with frames, and the depth maps look reasonable\n",
    "    \n",
    "#### Then, you can input your own data:\n",
    "- Replace the values of the three variables below\n",
    "  - **input_frames**: the path to the folder which contains your video frames\n",
    "  - **input_recon**: the path to the folder which contains your sparse reconstruction. For input format, we use the COLMAP format defined here (https://colmap.github.io/format.html). This folder should contain three files: `points2D.txt`, `images.txt`, and `cameras.txt`. Since the COLMAP format does not natively include information about whether or not a frame is a keyframe (since it's not originally intended for SLAM systems), we interpret this information from the POINTS2D[] in `images.txt`. That is, if a given image has a nonzero number of POINTS2D, we assume it is a keyframe. Note that the COLMAP format must be TXT and not BIN.\n",
    "  - **output_folder**: the path to the folder where you want the output saved\n",
    "\n",
    "This Python notebook is intended as a reference implementation for research purposes. Note that while this implementation is feature-complete, it is an unoptimized Python port of the version used for experiments in the paper, so performance will be much worse than what is reported. Please refer to the paper for more accurate timing results and details on how to further optimize this implementation. Additionally, while the linear system constraints used here are the same as in the paper, the solver is not the same, and therefore the results are not guaranteed to be identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_frames = \"sample_data/frames/\"\n",
    "input_colmap = \"sample_data/reconstruction/\"\n",
    "output_folder = \"output/\"\n",
    "\n",
    "dump_debug_images = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm parameters. See the paper for details.\n",
    "\n",
    "tau_high = 0.1\n",
    "tau_low = 0.1\n",
    "tau_flow = 0.2\n",
    "k_I = 5\n",
    "k_T = 7\n",
    "k_F = 31\n",
    "lambda_d = 1\n",
    "lambda_t = 0.01\n",
    "lambda_s = 1\n",
    "\n",
    "num_solver_iterations = 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simplified COLMAP importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reconstruction:\n",
    "    def __init__(self):\n",
    "        self.cameras = {}\n",
    "        self.views = {}\n",
    "        self.points3d = {}\n",
    "        self.min_view_id = -1\n",
    "        self.max_view_id = -1\n",
    "        self.image_folder = \"\"\n",
    "    \n",
    "    def ViewIds(self):\n",
    "        return list(self.views.keys())\n",
    "    \n",
    "    def GetNeighboringKeyframes(self, view_id):\n",
    "        previous_keyframe = -1\n",
    "        next_keyframe = -1\n",
    "        for idx in range(view_id - 1, self.min_view_id, -1):\n",
    "            if idx not in self.views:\n",
    "                continue\n",
    "            if self.views[idx].IsKeyframe():\n",
    "                previous_keyframe = idx\n",
    "                break\n",
    "        for idx in range(view_id + 1, self.max_view_id):\n",
    "            if idx not in self.views:\n",
    "                continue\n",
    "            if self.views[idx].IsKeyframe():\n",
    "                next_keyframe = idx\n",
    "                break\n",
    "        if previous_keyframe < 0 or next_keyframe < 0:\n",
    "            return np.array([])\n",
    "        return [previous_keyframe, next_keyframe]\n",
    "    \n",
    "    def GetReferenceFrames(self, view_id):\n",
    "        kf = self.GetNeighboringKeyframes(view_id)\n",
    "        if (len(kf) < 2):\n",
    "            return []\n",
    "        dist = np.linalg.norm(self.views[kf[1]].Position() -\\\n",
    "                              self.views[kf[0]].Position()) / 2\n",
    "        pos = self.views[view_id].Position()\n",
    "        ref = []\n",
    "        for idx in range(view_id + 1, self.max_view_id):\n",
    "            if idx not in self.views:\n",
    "                continue\n",
    "            if (np.linalg.norm(pos -\\\n",
    "                              self.views[idx].Position()) > dist):\n",
    "                ref.append(idx)\n",
    "                break\n",
    "        for idx in range(view_id - 1, self.min_view_id, -1):\n",
    "            if idx not in self.views:\n",
    "                continue\n",
    "            if (np.linalg.norm(pos -\\\n",
    "                              self.views[idx].Position()) > dist):\n",
    "                ref.append(idx)\n",
    "                break\n",
    "        return ref\n",
    "\n",
    "    def GetImage(self, view_id):\n",
    "        return self.views[view_id].GetImage(self.image_folder)\n",
    "    \n",
    "    def GetSparseDepthMap(self, frame_id):\n",
    "        camera = self.cameras[self.views[frame_id].camera_id]\n",
    "        view = self.views[frame_id]\n",
    "        view_pos = view.Position()\n",
    "        depth_map = np.zeros((camera.height, camera.width), dtype=np.float32)\n",
    "        for point_id, coord in view.points2d.items():\n",
    "            pos3d = self.points3d[point_id].position3d\n",
    "            depth = np.linalg.norm(pos3d - view_pos)\n",
    "            depth_map[int(coord[1]), int(coord[0])] = depth\n",
    "        return depth_map\n",
    "    \n",
    "    def Print(self):\n",
    "        print(\"Found \" + str(len(self.views)) + \" cameras.\")\n",
    "        for id in self.cameras:\n",
    "            self.cameras[id].Print()\n",
    "        print(\"Found \" + str(len(self.views)) + \" frames.\")\n",
    "        for id in self.views:\n",
    "            self.views[id].Print()\n",
    "\n",
    "class Point:\n",
    "    def __init__(self):\n",
    "        self.id = -1\n",
    "        self.position3d = np.zeros(3, float)\n",
    "    \n",
    "            \n",
    "class Camera:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.id = -1\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "        self.focal = np.zeros(2,float)\n",
    "        self.principal = np.zeros(2,float)\n",
    "        self.model = \"\"\n",
    "    \n",
    "    def Print(self):\n",
    "        print(\"Camera \" + str(self.id))\n",
    "        print(\"-Image size: (\" + str(self.width) + \\\n",
    "            \", \" + str(self.height) + \")\")\n",
    "        print(\"-Focal: \" + str(self.focal))\n",
    "        print(\"-Model: \" + self.model)\n",
    "        print(\"\")\n",
    "\n",
    "class View:    \n",
    "    def __init__(self):\n",
    "        self.id = -1\n",
    "        self.orientation = Quaternion()\n",
    "        self.translation = np.zeros(3, float)\n",
    "        self.points2d = {}\n",
    "        self.camera_id = -1\n",
    "        self.name = \"\"\n",
    "    \n",
    "    def IsKeyframe(self):\n",
    "        return len(self.points2d) > 0\n",
    "    \n",
    "    def Rotation(self):\n",
    "        return self.orientation.rotation_matrix\n",
    "    \n",
    "    def Position(self):\n",
    "        return self.orientation.rotate(self.translation)\n",
    "    \n",
    "    def GetImage(self, image_folder):\n",
    "        mat = cv2.imread(image_folder + \"/\" + self.name)\n",
    "        # Check that we loaded correctly.\n",
    "        assert mat is not None, \\\n",
    "            \"Image \" + self.name + \" was not found in \" \\\n",
    "            + image_folder\n",
    "        return mat\n",
    "    \n",
    "    def Print(self):\n",
    "        print(\"Frame \" + str(self.id) + \": \" + self.name)\n",
    "        print(\"Rotation: \\n\" + \\\n",
    "            str(self.Rotation()))\n",
    "        print(\"Position: \\n\" + \\\n",
    "            str(self.Position()))\n",
    "        print(\"\")\n",
    "        \n",
    "def ReadColmapCamera(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    line = file.readline()\n",
    "    cameras = {}\n",
    "    while (line):\n",
    "        if (line[0] != '#'):\n",
    "            tokens = line.split()\n",
    "            id_value = int(tokens[0])\n",
    "            cameras[id_value] = Camera()\n",
    "            cameras[id_value].id = id_value\n",
    "            cameras[id_value].model = tokens[1]\n",
    "            # Currently we're assuming that the camera model\n",
    "            # is in the SIMPLE_RADIAL format\n",
    "            assert(cameras[id_value].model == \"PINHOLE\")\n",
    "            cameras[id_value].width = int(tokens[2])\n",
    "            cameras[id_value].height = int(tokens[3])\n",
    "            cameras[id_value].focal[0] = float(tokens[4])\n",
    "            cameras[id_value].focal[1] = float(tokens[5])\n",
    "            cameras[id_value].principal[0] = float(tokens[6])\n",
    "            cameras[id_value].principal[1] = float(tokens[7])\n",
    "        line = file.readline()\n",
    "    return cameras;\n",
    "\n",
    "def ReadColmapImages(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    line = file.readline()\n",
    "    views = {}\n",
    "    while (line):\n",
    "        if (line[0] != '#'):\n",
    "            tokens = line.split()\n",
    "            id_value = int(tokens[0])\n",
    "            views[id_value] = View()\n",
    "            views[id_value].id = id_value\n",
    "            views[id_value].orientation = Quaternion(float(tokens[1]), \\\n",
    "                                                     float(tokens[2]), \\\n",
    "                                                     float(tokens[3]), \\\n",
    "                                                     float(tokens[4]))\n",
    "            views[id_value].translation[0] = float(tokens[5])\n",
    "            views[id_value].translation[1] = float(tokens[6])\n",
    "            views[id_value].translation[2] = float(tokens[7])\n",
    "            views[id_value].camera_id = int(tokens[8])\n",
    "            views[id_value].name = tokens[9]\n",
    "            line = file.readline()\n",
    "            tokens = line.split()\n",
    "            views[id_value].points2d = {}\n",
    "            for idx in range(0, len(tokens) // 3):\n",
    "                point_id = int(tokens[idx * 3 + 2])\n",
    "                coord = np.array([float(tokens[idx * 3 + 0]), \\\n",
    "                         float(tokens[idx * 3 + 1])])\n",
    "                views[id_value].points2d[point_id] = coord\n",
    "            \n",
    "            # Read the observations...\n",
    "        line = file.readline()\n",
    "    return views\n",
    "           \n",
    "def ReadColmapPoints(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    line = file.readline()\n",
    "    points = {}\n",
    "    while (line):\n",
    "        if (line[0] != '#'):\n",
    "            tokens = line.split()\n",
    "            id_value = int(tokens[0])\n",
    "            points[id_value] = Point()\n",
    "            points[id_value].id = id_value\n",
    "            points[id_value].position3d = np.array([float(tokens[1]), \\\n",
    "                                        float(tokens[2]), \\\n",
    "                                        float(tokens[3])])\n",
    "            \n",
    "        line = file.readline()\n",
    "    return points\n",
    "        \n",
    "            \n",
    "    \n",
    "def ReadColmap(poses_folder, images_folder):\n",
    "    # Read the cameras (intrinsics)\n",
    "    recon = Reconstruction()\n",
    "    recon.image_folder = images_folder\n",
    "    recon.cameras = ReadColmapCamera(poses_folder + \"/cameras.txt\")\n",
    "    recon.views = ReadColmapImages(poses_folder + \"/images.txt\")\n",
    "    recon.points3d = ReadColmapPoints(poses_folder + \"/points3D.txt\")\n",
    "    recon.min_view_id = min(list(recon.views.keys()))\n",
    "    recon.max_view_id = max(list(recon.views.keys()))\n",
    "    print(\"Number of points: \" + str(len(recon.points3d)))\n",
    "    print(\"Number of frames: \" + str(len(recon.views)))\n",
    "    #assert len(recon.views) == (recon.max_view_id - recon.min_view_id) + 1, \"Min\\max: \" + str(recon.max_view_id) + \" \" + str(recon.min_view_id)\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The densification code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flow_color\n",
    "\n",
    "dis = DISOpticalFlow.create(2)\n",
    "def GetFlow(image1, image2):\n",
    "    flow = np.zeros((image1.shape[0], image1.shape[1], 2), np.float32)\n",
    "    flow = dis.calc(\\\n",
    "        cv2.cvtColor(image1,cv2.COLOR_BGR2GRAY),\\\n",
    "        cv2.cvtColor(image2,cv2.COLOR_BGR2GRAY), flow)\n",
    "    return flow\n",
    "\n",
    "def AbsoluteMaximum(images):\n",
    "    assert(len(images) > 0)\n",
    "    output = images[0]\n",
    "    for i in range(1,len(images)):\n",
    "        output[np.abs(images[i]) > np.abs(output)] = images[i][np.abs(images[i]) > np.abs(output)]\n",
    "    return output\n",
    "\n",
    "def GetImageGradient(image):\n",
    "    xr,xg,xb = cv2.split(cv2.Sobel(image,cv2.CV_64F,1,0,ksize=5))\n",
    "    yr,yg,yb = cv2.split(cv2.Sobel(image,cv2.CV_64F,0,1,ksize=5))\n",
    "    img_grad_x = AbsoluteMaximum([xr,xg,xb])\n",
    "    img_grad_y = AbsoluteMaximum([yr,yg,yb])\n",
    "    \n",
    "    return img_grad_x, img_grad_y\n",
    "\n",
    "def GetGradientMagnitude(img_grad_x, img_grad_y):\n",
    "    img_grad_magnitude = cv2.sqrt((img_grad_x * img_grad_x) \\\n",
    "                                  + (img_grad_y * img_grad_y))\n",
    "    return img_grad_magnitude\n",
    "\n",
    "def GetFlowGradientMagnitude(flow, img_grad_x, img_grad_y):\n",
    "    x1,x2 = cv2.split(cv2.Sobel(flow,cv2.CV_64F,1,0,ksize=5))\n",
    "    y1,y2 = cv2.split(cv2.Sobel(flow,cv2.CV_64F,0,1,ksize=5))\n",
    "    flow_grad_x = AbsoluteMaximum([x1,x2])\n",
    "    flow_grad_y = AbsoluteMaximum([y1,y2])\n",
    "    flow_gradient_magnitude = cv2.sqrt((flow_grad_x * flow_grad_x) \\\n",
    "                                   + (flow_grad_y * flow_grad_y))\n",
    "    reliability = np.zeros((flow.shape[0], flow.shape[1]))\n",
    "\n",
    "    for x in range(0, flow.shape[0]):\n",
    "        for y in range(1, flow.shape[1]):\n",
    "            magn = (img_grad_x[x,y] * img_grad_x[x,y]) + \\\n",
    "                (img_grad_y[x,y] * img_grad_y[x,y])\n",
    "            gradient_dir = np.array((img_grad_y[x,y], img_grad_x[x,y]))\n",
    "            if (np.linalg.norm(gradient_dir) == 0):\n",
    "                reliability[x,y] = 0\n",
    "                continue\n",
    "            gradient_dir = gradient_dir / np.linalg.norm(gradient_dir)\n",
    "            center_pixel = np.array((x,y))\n",
    "            p0 = center_pixel + gradient_dir\n",
    "            p1 = center_pixel - gradient_dir\n",
    "            if p0[0] < 0 or p1[0] < 0 or p0[1] < 0 or p1[1] < 0 \\\n",
    "                or p0[0] >= flow.shape[0] or p0[1] >= flow.shape[1] or \\\n",
    "                p1[0] >= flow.shape[0] or p1[1] >= flow.shape[1]:\n",
    "                reliability[x,y] = -1000\n",
    "                continue\n",
    "            f0 = flow[int(p0[0]), int(p0[1])].dot(gradient_dir)\n",
    "            f1 = flow[int(p1[0]), int(p1[1])].dot(gradient_dir)\n",
    "            reliability[x,y] = f1 - f0\n",
    "\n",
    "    return flow_gradient_magnitude, reliability\n",
    "\n",
    "def GetSoftEdges(image, flows):\n",
    "    img_grad_x, img_grad_y = GetImageGradient(image)\n",
    "    img_grad_magnitude = GetGradientMagnitude(img_grad_x, img_grad_y)\n",
    "    if (dump_debug_images):\n",
    "        plt.imsave(output_folder + \"/image_gradient_\" + recon.views[frame].name, \\\n",
    "                img_grad_magnitude)\n",
    "    flow_gradient_magnitude = np.zeros(img_grad_magnitude.shape)\n",
    "    \n",
    "    max_reliability = np.zeros(flow_gradient_magnitude.shape)\n",
    "    i = 0\n",
    "    for flow in flows:\n",
    "        magnitude, reliability = GetFlowGradientMagnitude(flow, img_grad_x, img_grad_y)\n",
    "        if (dump_debug_images):\n",
    "            plt.imsave(output_folder + \"/flow_\" + str(i) + \"_\" + recon.views[frame].name, \\\n",
    "                    flow_color.computeImg(flow))            \n",
    "            plt.imsave(output_folder + \"/reliability_\" + str(i) + \"_\" + recon.views[frame].name, \\\n",
    "                    reliability)\n",
    "        flow_gradient_magnitude[reliability > max_reliability] = magnitude[reliability > max_reliability]\n",
    "        i += 1\n",
    "        \n",
    "    if (dump_debug_images):\n",
    "        plt.imsave(output_folder + \"/flow_gradient_\" + recon.views[frame].name, \\\n",
    "                flow_gradient_magnitude)\n",
    "    flow_gradient_magnitude = \\\n",
    "        cv2.GaussianBlur(flow_gradient_magnitude,(k_F, k_F),0)\n",
    "    flow_gradient_magnitude *= img_grad_magnitude\n",
    "    flow_gradient_magnitude /= flow_gradient_magnitude.max()\n",
    "    return flow_gradient_magnitude\n",
    "    \n",
    "def Canny(soft_edges, image):\n",
    "    image = cv2.GaussianBlur(image, (k_I, k_I), 0)\n",
    "    xr,xg,xb = cv2.split(cv2.Sobel(image,cv2.CV_64F,1,0,ksize=5))\n",
    "    yr,yg,yb = cv2.split(cv2.Sobel(image,cv2.CV_64F,0,1,ksize=5))\n",
    "    img_gradient = cv2.merge((AbsoluteMaximum([xr,xg,xb]),AbsoluteMaximum([yr,yg,yb])))\n",
    "    \n",
    "    TG22 = 13573\n",
    "    \n",
    "    gx,gy = cv2.split(img_gradient * (2**15))\n",
    "    mag = cv2.sqrt((gx * gx) \\\n",
    "                    + (gy * gy))\n",
    "    seeds = []\n",
    "    edges = np.zeros(mag.shape)\n",
    "    for x in range(1, img_gradient.shape[0] - 1):\n",
    "        for y in range(1, img_gradient.shape[1] - 1):\n",
    "            ax = int(abs(gx[x,y]))\n",
    "            ay = int(abs(gy[x,y])) << 15\n",
    "            tg22x = ax * TG22\n",
    "            m = mag[x,y]\n",
    "            if (ay < tg22x):\n",
    "                if (m > mag[x,y-1] and\\\n",
    "                   m >= mag[x,y+1]):\n",
    "                    #suppressed[x,y] = m\n",
    "                    if (m > tau_high and soft_edges[x,y] > tau_flow):\n",
    "                        seeds.append((x,y))\n",
    "                        edges[x,y] = 255\n",
    "                    elif (m > tau_low):\n",
    "                        edges[x,y] = 1\n",
    "            else:\n",
    "                tg67x = tg22x + (ax << 16)\n",
    "                if (ay > tg67x):\n",
    "                    if (m > mag[x+1,y] and m >= mag[x-1,y]):\n",
    "                        if (m > tau_high and soft_edges[x,y] > tau_flow):\n",
    "                            seeds.append((x,y))\n",
    "                            edges[x,y] = 255\n",
    "                        elif (m > tau_low):\n",
    "                            edges[x,y] = 1\n",
    "                else:\n",
    "                    if (int(gx[x,y]) ^ int(gy[x,y]) < 0):\n",
    "                        if (m > mag[x-1,y+1] and m >= mag[x+1,y-1]):\n",
    "                            if (m > tau_high and soft_edges[x,y] > tau_flow):\n",
    "                                seeds.append((x,y))\n",
    "                                edges[x,y] = 255\n",
    "                            elif (m > tau_low):\n",
    "                                edges[x,y] = 1\n",
    "                    else:\n",
    "                        if (m > mag[x-1,y-1] and m > mag[x+1,y+1]):\n",
    "                            if (m > tau_high and soft_edges[x,y] > tau_flow):\n",
    "                                seeds.append((x,y))\n",
    "                                edges[x,y] = 255\n",
    "                            elif (m > tau_low):\n",
    "                                edges[x,y] = 1\n",
    "    w = img_gradient.shape[0] - 1\n",
    "    h = img_gradient.shape[1] - 1\n",
    "    if (dump_debug_images):\n",
    "        plt.imsave(output_folder + \"/edge_seeds_\" + recon.views[frame].name, \\\n",
    "            edges == 255)\n",
    "        plt.imsave(output_folder + \"/edge_all_possible_\" + recon.views[frame].name, \\\n",
    "            edges == 1)\n",
    "    while len(seeds) > 0:\n",
    "        (x,y) = seeds.pop()\n",
    "        \n",
    "        if (x < w and y < h and edges[x+1,y+1] == 1):\n",
    "            edges[x+1,y+1] = 255\n",
    "            seeds.append((x+1,y+1))\n",
    "        if (x > 0 and y < h and edges[x-1,y+1] == 1):\n",
    "            edges[x-1,y+1] = 255\n",
    "            seeds.append((x-1,y+1))\n",
    "        if (y < h and edges[x,y+1] == 1):\n",
    "            edges[x,y+1] = 255\n",
    "            seeds.append((x,y+1))\n",
    "        if (x < w and y > 0 and edges[x+1,y-1] == 1):\n",
    "            edges[x+1,y-1] = 255\n",
    "            seeds.append((x+1,y-1))\n",
    "        if (x > 0 and y > 0 and edges[x-1,y-1] == 1):\n",
    "            edges[x-1,y-1] = 255\n",
    "            seeds.append((x-1,y-1))\n",
    "        if (y > 0 and edges[x,y-1] == 1):\n",
    "            edges[x,y-1] = 255\n",
    "            seeds.append((x,y-1))\n",
    "        if (x < w and edges[x+1,y] == 1):\n",
    "            edges[x+1,y] = 255\n",
    "            seeds.append((x+1,y))\n",
    "        if (x > 0 and edges[x-1,y] == 1):\n",
    "            edges[x-1,y] = 255\n",
    "            seeds.append((x-1,y))\n",
    "    edges[edges == 1] = 0\n",
    "    return edges\n",
    "    \n",
    "def GetInitialization(sparse_points, last_depth_map):\n",
    "    initialization = sparse_points.copy()\n",
    "    if last_depth_map.size > 0:\n",
    "        initialization[last_depth_map > 0] = 1.0 / last_depth_map[last_depth_map > 0]\n",
    "    \n",
    "    w = edges.shape[0]\n",
    "    h = edges.shape[1]\n",
    "    last_known = -1\n",
    "    first_known = -1\n",
    "    for col in range(0,w):\n",
    "        for row in range(0,h):\n",
    "            if (sparse_points[col, row] > 0):\n",
    "                last_known = 1.0 / sparse_points[col, row]\n",
    "            elif (initialization[col, row] > 0):\n",
    "                last_known = initialization[col, row]\n",
    "            if (first_known < 0):\n",
    "                first_known = last_known\n",
    "            initialization[col, row] = last_known\n",
    "    initialization[initialization < 0] = first_known\n",
    "    \n",
    "    return initialization\n",
    "    \n",
    "    \n",
    "def DensifyFrame(sparse_points, hard_edges, soft_edges, last_depth_map):\n",
    "    w = sparse_points.shape[0]\n",
    "    h = sparse_points.shape[1]\n",
    "    num_pixels = w * h\n",
    "    A = scipy.sparse.dok_matrix((num_pixels * 3, num_pixels), dtype=np.float32)\n",
    "    A[A > 0] = 0\n",
    "    A[A < 0] = 0\n",
    "    b = np.zeros(num_pixels * 3, dtype=np.float32)\n",
    "    x0 = np.zeros(num_pixels, dtype=np.float32)\n",
    "    num_entries = 0\n",
    "    \n",
    "    smoothness = np.maximum(1 - soft_edges, 0)\n",
    "    smoothness_x = np.zeros((w,h), dtype=np.float32)\n",
    "    smoothness_y = np.zeros((w,h), dtype=np.float32)\n",
    "    initialization = GetInitialization(sparse_points, last_depth_map)\n",
    "                             \n",
    "    if (dump_debug_images):\n",
    "        plt.imsave(output_folder + \"/solver_initialization_\" + recon.views[frame].name, \\\n",
    "                initialization)\n",
    "        plt.imsave(output_folder + \"/sparse_points_\" + recon.views[frame].name, \\\n",
    "                sparse_points)\n",
    "        plt.imsave(output_folder + \"/soft_edges_\" + recon.views[frame].name, \\\n",
    "                soft_edges)\n",
    "        plt.imsave(output_folder + \"/hard_edges_\" + recon.views[frame].name, \\\n",
    "                hard_edges)\n",
    "    \n",
    "    for row in range(1,h - 1):\n",
    "        for col in range(1,w - 1):\n",
    "            x0[col + row * w] = initialization[col, row]\n",
    "            # Add the data constraints\n",
    "            if (sparse_points[col, row] > 0.00):\n",
    "                A[num_entries, col + row * w] = lambda_d\n",
    "                b[num_entries] = (1.0 / sparse_points[col, row]) * lambda_d\n",
    "                num_entries += 1\n",
    "            elif (last_depth_map.size > 0 and last_depth_map[col, row] > 0):\n",
    "                A[num_entries, col + row * w] = lambda_t\n",
    "                b[num_entries] = (1.0 / last_depth_map[col, row]) * lambda_t\n",
    "                num_entries += 1\n",
    "    \n",
    "            # Add the smoothness constraints\n",
    "            smoothness_weight = lambda_s * min(smoothness[col, row], \\\n",
    "                                               smoothness[col - 1, row])\n",
    "            if (hard_edges[col, row] == hard_edges[col - 1, row]):\n",
    "                smoothness_x[col,row] = smoothness_weight\n",
    "                A[num_entries, (col - 1) + row * w] = smoothness_weight\n",
    "                A[num_entries, col + row * w] = -smoothness_weight\n",
    "                b[num_entries] = 0\n",
    "                num_entries += 1\n",
    "            \n",
    "            smoothness_weight = lambda_s * min(smoothness[col,row], \\\n",
    "                                               smoothness[col, row - 1])\n",
    "            if (hard_edges[col,row] == hard_edges[col, row - 1]):\n",
    "                smoothness_y[col,row] = smoothness_weight\n",
    "                A[num_entries, col + (row - 1) * w] = smoothness_weight\n",
    "                A[num_entries, col + row * w] = -smoothness_weight\n",
    "                b[num_entries] = 0\n",
    "                num_entries += 1\n",
    "    \n",
    "    \n",
    "    # Solve the system\n",
    "    if (dump_debug_images):\n",
    "        plt.imsave(output_folder + \"/solver_smoothness_x_\" + recon.views[frame].name, \\\n",
    "                smoothness_x)\n",
    "        plt.imsave(output_folder + \"/solver_smoothness_y_\" + recon.views[frame].name, \\\n",
    "                smoothness_y)\n",
    "\n",
    "    [x,info] = scipy.sparse.linalg.cg(A.transpose() * A, \\\n",
    "                                      A.transpose() * b, x0, 1e-05, num_solver_iterations)\n",
    "    if info < 0:\n",
    "        print(\"====> Error! Illegal input!\")\n",
    "    elif info > 0:\n",
    "        print(\"====> Ran \" + str(info) + \" solver iterations.\")\n",
    "    else:\n",
    "        print(\"====> Solver converged!\")\n",
    "    \n",
    "    depth = np.zeros(sparse_points.shape, dtype=np.float32)\n",
    "\n",
    "    # Copy back the pixels\n",
    "    for row in range(0,h):\n",
    "        for col in range(0,w):\n",
    "            depth[col,row] = 1.0 / x[col + row * w]\n",
    "\n",
    "    return depth\n",
    "\n",
    "def TemporalMedian(depth_maps):\n",
    "    lists = {}\n",
    "    depth_map = depth_maps[0].copy()\n",
    "    h = depth_map.shape[0]\n",
    "    w = depth_map.shape[1]\n",
    "    for row in range(0,h):\n",
    "        for col in range(0,w):\n",
    "            values = []\n",
    "            for img in depth_maps:\n",
    "                if (img[row,col] > 0):\n",
    "                    values.append(img[row, col])\n",
    "            if len(values) > 0:\n",
    "                depth_map[row,col] = np.median(np.array(values))\n",
    "            else:\n",
    "                depth_map[row,col] = 0\n",
    "    return depth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recon = ReadColmap(input_colmap, input_frames)\n",
    "\n",
    "last_depths = []\n",
    "last_depth = np.array([])\n",
    "\n",
    "# Use the first two keyframes as initialization for the system. \n",
    "# The depth maps for these initialization frames will not be saved.\n",
    "skip_frames = \\\n",
    "    recon.GetNeighboringKeyframes(recon.GetNeighboringKeyframes(recon.ViewIds()[15])[0])[1]\n",
    "\n",
    "print(\"Using the first \" + str(skip_frames) + \" frames to initialize (these won't be saved).\")\n",
    "\n",
    "for frame in recon.ViewIds():\n",
    "    reference_frames = recon.GetReferenceFrames(frame)\n",
    "    if (len(reference_frames) == 0):\n",
    "        print(\"==> Skipping frame \" + recon.views[frame].name + \\\n",
    "              \", No prior keyframes.\")\n",
    "        continue\n",
    "    print(\"==> Processing frame \" + recon.views[frame].name)\n",
    "    base_img = recon.GetImage(frame)\n",
    "    flows = []\n",
    "    for ref in reference_frames:\n",
    "        ref_img = recon.GetImage(ref) \n",
    "        flows.append(GetFlow(base_img, ref_img))\n",
    "    soft_edges = GetSoftEdges(base_img, flows)\n",
    "    edges = Canny(soft_edges, base_img)\n",
    "    \n",
    "    last_keyframe = frame\n",
    "    if not recon.views[frame].IsKeyframe():\n",
    "        neighboring_keyframes = recon.GetNeighboringKeyframes(frame)\n",
    "        assert(len(neighboring_keyframes) > 1)\n",
    "        last_keyframe = neighboring_keyframes[0]\n",
    "    depth = DensifyFrame(recon.GetSparseDepthMap(last_keyframe), edges, \\\n",
    "                         soft_edges, last_depth)\n",
    "    last_depths.append(depth)\n",
    "    if (len(last_depths) > k_T):\n",
    "        last_depths.pop(0)\n",
    "    filtered_depth = TemporalMedian(last_depths)\n",
    "\n",
    "    # Skip the first 20 frames, to make sure the depths have converged.\n",
    "    if (frame >= skip_frames):\n",
    "        plt.imsave(output_folder + \"/\" + recon.views[frame].name, \\\n",
    "                   filtered_depth) \n",
    "        print(\"===> Depth saved to output as \" + recon.views[frame].name)\n",
    "    last_depth = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
